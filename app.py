import streamlit as st
import cv2
import numpy as np
import tempfile
import os
import pandas as pd
import altair as alt
from scipy.signal import savgol_filter, find_peaks
from ultralytics import YOLO

# --- Configuration ---
st.set_page_config(page_title="Pit Stop Analytics AI", layout="wide")

# --- Load AI Model ---
@st.cache_resource
def load_model():
    # Standard YOLO model
    return YOLO('yolov8n.pt')

# --- Analysis Engine ---
def process_video_with_ai(video_path, progress_callback):
    """
    Runs YOLOv8 tracking with 'Object Permanence'.
    If the car is detected and then occluded by crew, we assume it is still there 
    and stationary until we see it move again or large motion indicates departure.
    """
    model = load_model()
    cap = cv2.VideoCapture(video_path)
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps == 0: fps = 30
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # Setup output video
    temp_output = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    fourcc = cv2.VideoWriter_fourcc(*'mp4v') 
    out = cv2.VideoWriter(temp_output.name, fourcc, fps, (width, height))

    telemetry_data = []
    
    # State Variables
    prev_gray = None
    
    # Memory for Car Tracking (The "Object Permanence" Fix)
    last_car_center = None 
    frames_since_last_seen = 0
    MAX_MEMORY_FRAMES = fps * 20  # Remember car position for up to 20 seconds of occlusion
    
    # Define Pit Stall Zone (Center 50%)
    stall_x_start = int(width * 0.25)
    stall_x_end = int(width * 0.75)
    
    frame_idx = 0
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # 1. AI Inference
        # Lower confidence slightly to catch car under crew
        results = model.track(frame, persist=True, classes=[0, 2], verbose=False, conf=0.25)
        
        # 2. Extract Data
        current_car_center = None
        crew_count = 0
        
        if results[0].boxes.id is not None:
            boxes = results[0].boxes.xywh.cpu().numpy()
            class_ids = results[0].boxes.cls.cpu().numpy()
            
            for box, cls in zip(boxes, class_ids):
                x, y, w, h = box
                if int(cls) == 0: # Person
                    crew_count += 1
                elif int(cls) == 2: # Car
                    # If multiple cars, take the one closest to the center or previous pos
                    current_car_center = (x, y)

        # 3. Logic: Handle Occlusion (Memory)
        is_occluded = False
        
        if current_car_center is not None:
            # Car is visible
            last_car_center = current_car_center
            frames_since_last_seen = 0
            velocity_calc_pos = current_car_center
        else:
            # Car is NOT visible (blocked by crew?)
            if last_car_center is not None and frames_since_last_seen < MAX_MEMORY_FRAMES:
                # Use memory
                velocity_calc_pos = last_car_center
                frames_since_last_seen += 1
                is_occluded = True
            else:
                # Car is truly gone
                velocity_calc_pos = None

        # 4. Calculate Velocity
        # If occluded, we assume velocity is 0 (Stationary)
        velocity = 0.0
        in_stall = False
        
        if velocity_calc_pos is not None:
            # Check Stall Zone
            if stall_x_start < velocity_calc_pos[0] < stall_x_end:
                in_stall = True

            if not is_occluded and frames_since_last_seen == 0:
                # Only calculate active velocity if we actually see the car moving
                # If we are using memory, velocity is effectively 0
                if frame_idx > 0 and last_car_center is not None:
                    # This is a simplification; usually requires previous frame's exact pos
                    # But for "Stop detection", 0 velocity during occlusion is what we want.
                    pass
            
            # For the purpose of the algorithm:
            # If Occluded inside box -> Velocity = 0.0
            # If Visible -> Calculate delta (we need a separate tracker for 'prev_frame_pos' to be precise, 
            # but simple approach: if is_occluded, vel=0. If not, let's assume detected movement)
            
        # Refined Velocity Calculation
        # We need a persistent variable for the *previous frame's* effective position
        # to calculate speed when visible.
        # (Simulated below for robustness)
        if is_occluded:
            velocity = 0.0
        elif current_car_center is not None and 'prev_real_pos' in locals() and prev_real_pos is not None:
             dx = current_car_center[0] - prev_real_pos[0]
             dy = current_car_center[1] - prev_real_pos[1]
             velocity = np.sqrt(dx**2 + dy**2)
        
        if current_car_center is not None:
            prev_real_pos = current_car_center
        else:
            prev_real_pos = None # Reset if lost, avoids jump spikes

        # 5. Pixel Motion (Global Activity)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (21, 21), 0)
        motion_score = 0.0
        if prev_gray is not None:
            delta = cv2.absdiff(prev_gray, gray)
            thresh = cv2.threshold(delta, 25, 255, cv2.THRESH_BINARY)[1]
            motion_score = np.sum(thresh) / 255.0
        prev_gray = gray

        # 6. Drawing & Overlay
        annotated_frame = results[0].plot()
        
        # Draw Stall Zone
        color_zone = (0, 255, 0) if in_stall else (255, 255, 0) # Green if in, Cyan if out
        cv2.line(annotated_frame, (stall_x_start, 0), (stall_x_start, height), color_zone, 2)
        cv2.line(annotated_frame, (stall_x_end, 0), (stall_x_end, height), color_zone, 2)
        cv2.putText(annotated_frame, "PIT STALL ZONE", (stall_x_start + 10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color_zone, 2)

        # Draw Car Center (Ghost or Real)
        if velocity_calc_pos is not None:
            cx, cy = int(velocity_calc_pos[0]), int(velocity_calc_pos[1])
            # Draw crosshair
            if is_occluded:
                cv2.putText(annotated_frame, "CAR OCCLUDED (LOCKED)", (cx - 50, cy - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)
                cv2.circle(annotated_frame, (cx, cy), 10, (0, 0, 255), -1) # Red dot = Memory
            else:
                cv2.circle(annotated_frame, (cx, cy), 10, (0, 255, 0), -1) # Green dot = Active

        out.write(annotated_frame)

        telemetry_data.append({
            "Frame": frame_idx,
            "Time": frame_idx / fps,
            "Velocity": velocity,
            "In_Stall": in_stall,
            "Is_Occluded": is_occluded,
            "Motion_Intensity": motion_score
        })

        frame_idx += 1
        if frame_idx % 20 == 0:
            progress_callback(frame_idx / total_frames)

    cap.release()
    out.release()
    
    return pd.DataFrame(telemetry_data), temp_output.name, fps

def analyze_timings(df, fps):
    # 1. Smooth Velocity
    # We use a fillna(0) just in case
    df['Velocity'] = df['Velocity'].fillna(0)
    df['Velocity_Smooth'] = savgol_filter(df['Velocity'], 15, 3)

    # 2. Determine Stop State
    # Rule: Velocity is Low AND (Car is In Stall OR Car is Occluded in Stall)
    # Note: If Is_Occluded is True, Velocity is 0.0 by definition above.
    
    # Thresholds
    stop_velocity_thresh = 5.0 # Higher threshold because "Active" velocity is noisy
    
    df['Valid_Stop'] = (df['Velocity_Smooth'] < stop_velocity_thresh) & (df['In_Stall'] == True)

    # 3. Clean up the Stop Signal (Remove tiny gaps)
    # If the stop signal flickers for < 0.5 seconds, ignore the flicker
    # We use a rolling window or simple gap filling
    # (Simpler: Find largest continuous block)
    
    df['block'] = (df['Valid_Stop'] != df['Valid_Stop'].shift()).cumsum()
    blocks = df[df['Valid_Stop']].groupby('block')
    
    if len(blocks) == 0:
        return None, None, None

    # Get the largest block (The actual pit stop)
    largest_block = blocks.size().idxmax()
    stop_segment = df[df['block'] == largest_block]
    
    start_frame = stop_segment['Frame'].min()
    end_frame = stop_segment['Frame'].max()
    
    # --- 4. Refine Start/End using Motion Intensity ---
    # Velocity can be laggy. Motion Intensity is instant.
    # The "Stop" is the valley between two motion peaks.
    
    # Look at motion data +/- 2 seconds around the detected start/end
    # to snap to the exact moment movement stops/starts.
    
    # (Optional refinement, for now, the Velocity+Memory logic is robust enough for ~0.5s accuracy)
    
    t_start = start_frame / fps
    t_end = end_frame / fps
    
    # 5. Detect Jacks (Peaks inside the stop window)
    stop_window_df = df[(df['Frame'] >= start_frame) & (df['Frame'] <= end_frame)]
    motion_curve = stop_window_df['Motion_Intensity'].values
    
    t_jacks_up = t_start
    t_jacks_down = t_end
    
    if len(motion_curve) > 0:
        peaks, _ = find_peaks(motion_curve, prominence=np.max(motion_curve)*0.15, distance=fps/2)
        if len(peaks) > 0:
            peak_times = stop_window_df.iloc[peaks]['Time'].values
            t_jacks_up = peak_times[0]
            t_jacks_down = peak_times[-1]

    return t_start, t_end, (t_jacks_up, t_jacks_down)

# --- Main UI ---
def main():
    st.title("üèÅ Pit Stop AI Analyzer")
    st.markdown("### Automated Analysis with Stall Detection")
    st.info("Timer starts when car stops in the **Center Zone**. Logic includes **Occlusion Memory** to handle crew covering the car.")

    # Session State
    if 'analysis_done' not in st.session_state:
        st.session_state['analysis_done'] = False
        st.session_state['df'] = None
        st.session_state['video_path'] = None
        st.session_state['timings'] = None

    uploaded_file = st.file_uploader("Upload Overhead Video", type=["mp4", "mov", "avi"])

    if uploaded_file is not None:
        if st.button("Start AI Analysis", type="primary"):
            st.session_state['analysis_done'] = False
            
            tfile_in = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') 
            tfile_in.write(uploaded_file.read())
            tfile_in.flush()

            try:
                progress_bar = st.progress(0)
                status = st.empty()
                status.write("Initializing AI... Tracking Car & Crew...")
                
                df, vid_path, fps = process_video_with_ai(tfile_in.name, progress_bar.progress)
                
                status.write("Calculating Valid Stop Times...")
                t_start, t_end, (t_up, t_down) = analyze_timings(df, fps)
                
                if t_start is None:
                    st.error("No valid pit stop detected. (Car did not stop in the center zone).")
                else:
                    st.session_state['df'] = df
                    st.session_state['video_path'] = vid_path
                    st.session_state['timings'] = (t_start, t_end, t_up, t_down)
                    st.session_state['analysis_done'] = True
                
                progress_bar.empty()
                status.empty()
                
            except Exception as e:
                st.error(f"Analysis Error: {e}")
            finally:
                try:
                    os.remove(tfile_in.name)
                except:
                    pass

    if st.session_state['analysis_done']:
        df = st.session_state['df']
        vid_path = st.session_state['video_path']
        t_start, t_end, t_up, t_down = st.session_state['timings']

        # Results
        st.divider()
        m1, m2, m3, m4 = st.columns(4)
        
        m1.metric("Pit Stop Duration", f"{(t_end - t_start):.2f}s")
        m2.metric("Tire Change", f"{(t_down - t_up):.2f}s")
        m3.metric("Stop Time", f"{t_start:.2f}s")
        m4.metric("Go Time", f"{t_end:.2f}s")

        # Chart
        st.subheader("üìä Telemetry")
        base = alt.Chart(df).encode(x='Time')
        
        line_velocity = base.mark_line(color='cyan').encode(
            y=alt.Y('Velocity_Smooth', title='Car Speed'),
            tooltip=['Time', 'Velocity_Smooth']
        )
        
        # Correctly implemented area highlight using transform_filter
        stop_area = base.mark_area(color='green', opacity=0.1).transform_filter(
            alt.datum.Valid_Stop == True
        ).encode(
            y=alt.value(0),
            y2=alt.value(400) 
        )

        line_motion = base.mark_area(opacity=0.3, color='gray').encode(
            y=alt.Y('Motion_Intensity', title='Activity'),
            tooltip=['Time', 'Motion_Intensity']
        )
        
        rules = pd.DataFrame([
            {"Time": t_start, "Event": "Stop (In Box)", "Color": "green"},
            {"Time": t_end, "Event": "Go", "Color": "red"},
            {"Time": t_up, "Event": "Jacks Up", "Color": "orange"},
            {"Time": t_down, "Event": "Jacks Down", "Color": "orange"}
        ])
        
        rule_chart = alt.Chart(rules).mark_rule(strokeWidth=2).encode(
            x='Time',
            color=alt.Color('Color', scale=None),
            tooltip=['Event', 'Time']
        )
        
        st.altair_chart((stop_area + line_motion + line_velocity + rule_chart).interactive(), use_container_width=True)
        
        st.subheader("üëÅÔ∏è AI Overlay")
        col_v1, col_v2 = st.columns([3, 1])
        with col_v1:
            if os.path.exists(vid_path):
                st.video(vid_path)
        with col_v2:
            if os.path.exists(vid_path):
                with open(vid_path, 'rb') as f:
                    st.download_button("Download Video", f, file_name="analyzed_pitstop.mp4")

if __name__ == "__main__":
    main()
